# -*- coding: utf-8 -*-
"""DeepCon Translation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mBAdcOpq3-CT4u_yOwDF7RwNMsRlfiDw
"""

# %%capture
# !pip install transformers torch sentencepiece transformers[sentencepiece] boto3

import boto3
from tqdm.notebook import tqdm
from transformers import MarianMTModel, MarianTokenizer

session = boto3.Session(
    aws_access_key_id='AKIA4QB2WTN57SCTNAGG',
    aws_secret_access_key='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',
)
s3 = session.resource('s3')
s3.meta.client.download_file(Bucket='mtacl', Key="helsinki_checkpoints_fr_3_epochs", Filename='model_checkpoints.zip')
!unzip model_checkpoints.zip

# utilities
def read_minute(path_to_file):
  with open(path_to_file, 'r') as f:
    minute = [line.strip() for line in f]  
  return minute

def translate_minutes(en_minutes: list):
  translated_minutes = []
  for source_sentence in tqdm(minute, total=len(minute)):
    translated = model.generate(**tokenizer(source_sentence, return_tensors="pt", padding=True))  
    translated_minutes.extend([tokenizer.decode(t, skip_special_tokens=True) for t in translated])
  return translated_minutes

def save_2_text(translated_minutes: list, path_to_file: str):
  with open(path_to_file, 'w') as filehandle:
    for listitem in translated_minutes:
        filehandle.write('%s\n' % listitem)

minute = read_minute("/content/minute.txt")

minute

model_checkpoints = "/content/checkpoint-12500"
tokenizer = MarianTokenizer.from_pretrained(model_checkpoints)
model = MarianMTModel.from_pretrained(model_checkpoints)

# translate English minutes to French
translated_minutes = translate_minutes(minute)

path_to_file = "/content/translated_minute.txt"
save_2_text(translated_minutes, path_to_file)
